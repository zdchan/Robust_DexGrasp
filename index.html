<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Robust Dexterous Grasping of General Objects from Single-view Perception.">
  <meta name="keywords" content="SingleView DexGrasp">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Robust Dexterous Grasping of General Objects from Single-view Perception</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-72PW1FZDE4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-72PW1FZDE4');
  </script>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RJ93D4865V"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-RJ93D4865V');
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Robust Dexterous Grasping of General Objects from Single-view Perception</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zdchan.github.io/">Hui Zhang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://zijianwu1121.github.io/">Zijian Wu</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=boUC8sYAAAAJ&hl=en">Linyi Huang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/sammyc">Sammy Christen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/SONG-Jie/jsongroas">Jie Song</a><sup>2,3</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH ZÃ¼rich, Switzerland</span>
            <br>
            <span class="author-block"><sup>2</sup>The Hong Kong University of Science and Technology (Guangzhou), China</span>
<!--             <br> -->
            <span class="author-block"><sup>3</sup>The Hong Kong University of Science and Technology, Hong Kong (China)</span>
          </div>

          <div class="is-size-5">
              *Equal Contribution
          </div>
          
<!--            <div class="is-size-5">
              <span class="author-block">  <b>Accepted by ECCV 2024</b></span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zdchan/RobustDexGrasp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section_video">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <video id="teaser" controls height="100%">
            <source src="graspxl.mp4"
                    type="video/mp4">
          </video>
        </div>
        <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin-top: 1.5rem;">
            Relying on single-view perception, our method achieves robust grasping of 500+ unseen objects with various shapes, sizes, materials, masses, and random poses. 
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="background-color: #f5f5f5; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
          <p>
            Robust grasping of various objects from single-view perception is fundamental for dexterous robots. Previous works often rely on fully observable objects, expert demonstrations, or static grasping poses, which restrict their generalization ability and adaptability to external disturbances. In this paper, we present a reinforcement-learning-based framework that enables zero-shot dynamic dexterous grasping of a wide range of unseen objects from single-view perception, while performing adaptive motions to external disturbances. We utilize a hand-centric object representation for shape feature extraction that emphasizes interaction-relevant local shapes, enhancing robustness to shape variance and uncertainty. To enable effective hand adaptation to disturbances with limited observations, we propose a mixed curriculum learning strategy, which first utilizes imitation learning to distill a policy trained with privileged real-time visual-tactile feedback, and gradually transfers to reinforcement learning to learn adaptive motions under disturbances caused by observation noises and dynamic randomization. Our experiments demonstrate strong generalization in grasping unseen objects with random poses, achieving success rates of 87.6% across 247,786 simulated objects and 85.3% across 512 real objects. We also demonstrate the robustness of our method to various disturbances, including unobserved object movement and external forces, through both quantitative and qualitative evaluations.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

<!--    &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--    <div class="columns is-centered has-text-centered">-->
<!--      <div class="column is-four-fifths">-->
<!--        <h2 class="title is-3">Video</h2>-->
<!--        <div class="publication-video">-->
<!--          <iframe width="560" height="315" src="https://www.youtube.com/embed/Q99t36qGZUU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->

<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--    &lt;!&ndash;/ Paper video. &ndash;&gt;-->
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <h2 class="title is-3 has-text-centered">Generated Motions</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop height="50%">
            <source src="shadow.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="50%">
            <source src="allegro.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="50%">
            <source src="knife1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="50%">
            <source src="knife2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="50%">
            <source src="earphone.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="50%">
            <source src="battery1.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
  <h3 class="title is-3 has-text-centered">Generalization</h3>
  <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin-bottom: 2rem;">
    Trained with only 20 objects in simulation, our method demonstrates exceptional generalization capability across 500+ unseen real objects with various physical properties and random poses.
  </h2>
    <div class="columns is-centered">
    <div class="column is-full-width has-text-centered">
      <div class="content">
        <video id="unzip_video" autoplay controls muted loop playsinline height="100%" style="max-width: 80%; margin: 0 auto;">
          <source src="large1.mp4"
                  type="video/mp4">
        </video>
        <div style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-top: 1rem;">
          <p class="has-text-centered" style="font-size: 1.1rem; margin: 0;">
            Robust grasping of diverse unseen objects with varying shapes, weights, and materials.
          </p>
        </div>
      </div>
    </div>
    </div>
    
    <div class="columns is-centered">
    <div class="column is-full-width has-text-centered">
      <div class="content">
        <video id="objective_video" autoplay controls muted loop playsinline height="100%" style="max-width: 80%; margin: 0 auto;">
          <source src="objective_new.mp4"
                  type="video/mp4">
        </video>
        <div style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-top: 1rem;">
          <p class="has-text-centered" style="font-size: 1.1rem; margin: 0;">
            Robust grasping of unseen objects with random poses on the table.
          </p>
        </div>
      </div>
    </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <h3 class="title is-3 has-text-centered">Robustness</h3>
  <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin-bottom: 2rem;">
    Trained by RL, our method shows great robustness and adaptability to internal and external disturbances.
  </h2>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="has-text-centered">
          <div class="content">
            <video id="multimat-video" autoplay controls muted loop playsinline height="60%" style="max-width: 80%; margin: 0 auto;">
              <source src="large2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 1rem auto; max-width: 80%;">
          Adaptive motions to observation noises and actual inaccuracies.
        </h2>
      
        <div class="has-text-centered">
          <div class="content">
            <video id="multimat-video2" autoplay controls muted loop playsinline height="100%" style="max-width: 80%; margin: 0 auto;">
              <source src="diverse.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 1rem auto; max-width: 80%;">
          Real-time adaptation to object movements and environmental changes.
        </h2>

        <div class="has-text-centered">
          <div class="content">
            <video id="unzip_video2" autoplay controls muted loop playsinline height="100%" style="max-width: 80%; margin: 0 auto;">
              <source src="robot_hand.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 1rem auto; max-width: 80%;">
          Maintaining stable grasps despite external disturbances and unexpected forces.
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <h3 class="title is-3 has-text-centered">Application</h3>
  <h2 class="subtitle has-text-centered" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin-bottom: 2rem;">
    Our method can be applied to real-world scenarios with complex environments and challenging tasks.
  </h2>
    
    <div class="columns is-centered">
    <div class="column is-full-width has-text-centered">
      <div class="content">
        <video id="objective_video" autoplay controls muted loop playsinline height="100%" style="max-width: 80%; margin: 0 auto;">
          <source src="objective_new.mp4"
                  type="video/mp4">
        </video>
        <div style="background-color: #f5f5f5; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-top: 1rem;">
          <p class="has-text-centered" style="font-size: 1.1rem; margin: 0;">
            Grasping target objects under the disturbances caused by other objects in a cluttered environment.
          </p>
        </div>
      </div>
    </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inProceedings{zhang2025SingleViewDexGrasp,
  title={Robust Dexterous Grasping of General Objects from Single-view Perception},
  author={Zhang, Hui and Wu, Zijian and Huang, Linyi and Christen, Sammy and Song, Jie},
  booktitle={Arxiv},
  year={2025}
}</code></pre>
  </div>
</section>

</body>
</html>
